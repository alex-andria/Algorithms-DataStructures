// Logs and Section Recap
    // Logs are the inverse of exponentiation
    // Log base 2 of 8 = 3
    // To what power equals 8? -> 3
    // We omit the 2.
    // log === log base 2
// Rule of Thumb roughly
    // Logarithm of a # roughly measure the number of times you can divide that number by 2 before you get a value that’s less than or equal to one.
    // Example
    // 8/2 = 4
    // 4/2 = 2
    // 2/2 = 1
    // log(8)=3
// Logarithm Complexity
    // O(log n)
// Who Cares?
    // Certain searching algos have log time complexity
    // Efficient sorting algos involve logs
    // Recursion sometimes involves log space complexity.
// Recap
    // To analyze the performance of an algorithm, we use Big O Notation
    // Big O Notation can give us a high level understanding of the time or space complexity of an algorithm
    // Big O Notation doesn’t care about precision, only about general trends (linear? Quadratic? constant?)
    // The time or space complexity (as measured by Big O) depends only on the algorithm, not the hardware used to run the algorithm
    // Big O Notation is everywhere, so gets lots of practice!
